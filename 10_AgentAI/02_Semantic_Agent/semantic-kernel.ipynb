{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel \n",
    "\n",
    "In this code sample, you will use the [Semantic Kernel](https://aka.ms/ai-agents-beginners/semantic-kernel) AI Framework to create a basic agent. \n",
    "\n",
    "The goal of this sample is to show you the steps that we will later use in the additional code samples when implementing the different agentic patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Needed Python Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.contents import FunctionCallContent, FunctionResultContent, StreamingTextContent\n",
    "from semantic_kernel.functions import kernel_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Client\n",
    "\n",
    "In this sample, we will use [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) for access to the LLM. \n",
    "\n",
    "The `ai_model_id` is defined as `gpt-4o-mini`. Try changing the model to another model available on the GitHub Models marketplace to see the different results. \n",
    "\n",
    "For us to use the `Azure Inference SDK` that is used for the `base_url` for GitHub Models, we will use the `OpenAIChatCompletion` connector within Semantic Kernel. There are also other [available connectors](https://learn.microsoft.com/semantic-kernel/concepts/ai-services/chat-completion) to use Semantic Kernel for other model providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Annotated\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "class NiFiErrorPlugin:\n",
    "    \"\"\"Returns a random NiFi error for debugging or simulation.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Common NiFi error messages\n",
    "        self.errors = [\n",
    "            \"S3 upload failed: Access Denied\",\n",
    "            \"Kafka processor restart loop detected\",\n",
    "            \"FlowFile queue overflow at connection: d365-outbound\",\n",
    "            \"Processor 'ConsumeKafka' stuck in 'Validating' state\",\n",
    "            \"Missing controller service: AWS_Credentials_Service\",\n",
    "            \"Connection timeout to remote system\",\n",
    "            \"JDBC connection pool exhausted\",\n",
    "            \"NiFi UI unresponsive due to high CPU usage\",\n",
    "            \"Deadlock detected between two processors\",\n",
    "            \"Backpressure object threshold reached\"\n",
    "        ]\n",
    "        self.last_error = None\n",
    "\n",
    "    @kernel_function(description=\"Returns a random NiFi error message for simulation or testing.\")\n",
    "    def get_random_nifi_error(self) -> Annotated[str, \"Returns a random NiFi error message\"]:\n",
    "        # Avoid repeating the same error\n",
    "        available_errors = self.errors.copy()\n",
    "        if self.last_error and len(available_errors) > 1:\n",
    "            available_errors.remove(self.last_error)\n",
    "\n",
    "        error = random.choice(available_errors)\n",
    "        self.last_error = error\n",
    "\n",
    "        return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = AsyncOpenAI(\n",
    "    api_key=os.environ.get(\"GITHUB_TOKEN\"), \n",
    "    base_url=\"https://models.inference.ai.azure.com/\",\n",
    ")\n",
    "\n",
    "# Create an AI Service that will be used by the `ChatCompletionAgent`\n",
    "chat_completion_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    async_client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Agent \n",
    "\n",
    "Below we create the Agent called `TravelAgent`.\n",
    "\n",
    "For this example, we are using very simple instructions. You can change these instructions to see how the agent responds differently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_INSTRUCTIONS = \"\"\"You are a helpful AI Agent that assists engineers in simulating and understanding NiFi pipeline issues.\n",
    "\n",
    "Important: When users describe a specific issue (e.g. \"Kafka stuck\" or \"S3 upload failed\"), focus your response on that specific case. Only suggest random NiFi errors when the user hasn't provided a clear problem.\n",
    "\n",
    "When the conversation begins, introduce yourself with this message:\n",
    "\"Hello! I'm your NiFi Debug Agent. I can help simulate, analyze, or explain common NiFi pipeline issues. Here are some things you can ask me:\n",
    "1. Simulate a random NiFi error\n",
    "2. Diagnose a known issue (e.g. Kafka stuck, S3 upload failures)\n",
    "3. Explain what a specific NiFi error message means\n",
    "4. Suggest how to fix common flow problems\n",
    "\n",
    "What NiFi issue are you facing or trying to simulate today?\"\n",
    "\n",
    "Always prioritize the user's input. If they mention a specific NiFi error or processor, address that directly instead of giving random messages.\n",
    "\"\"\"\n",
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service,\n",
    "    plugins=[NiFiErrorPlugin()],  # ðŸ›  nuovo plugin!\n",
    "    name=\"NiFiDebugAgent\",\n",
    "    instructions=AGENT_INSTRUCTIONS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Agents \n",
    "\n",
    "Now we can run the Agent by defining the `ChatHistory` and adding the `system_message` to it. We will use the `AGENT_INSTRUCTIONS` that we defined earlier. \n",
    "\n",
    "After these are defined, we create a `user_inputs` that will be what the user is sending to the agent. In this case, we have set this message to `Plan me a sunny vacation`. \n",
    "\n",
    "Feel free to change this message to see how the agent responds differently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom:10px'><div style='font-weight:bold'>User:</div><div style='margin-left:20px'>Simulate a NiFi error.</div></div><div style='margin-bottom:20px'><div style='font-weight:bold'>NiFiDebugAgent:</div><div style='margin-left:20px; white-space:pre-wrap'>A simulated NiFi error has occurred: **\"Deadlock detected between two processors.\"** \n",
       "\n",
       "This error typically indicates that two processors are waiting for each other to release resources, causing a complete halt in their operations. If you need help resolving this or want to simulate another issue, feel free to ask!</div></div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom:10px'><div style='font-weight:bold'>User:</div><div style='margin-left:20px'>Explain why Kafka might be stuck in restart loop.</div></div><div style='margin-bottom:20px'><div style='font-weight:bold'>NiFiDebugAgent:</div><div style='margin-left:20px; white-space:pre-wrap'>When Kafka is stuck in a restart loop, it can be due to several factors:\n",
       "\n",
       "1. **Configuration Issues**: Incorrect configurations, such as broker settings or topic configurations, can lead to failures at startup. For example, if the log directory is not properly set or if there are incorrect permissions on the log files, Kafka may fail to start.\n",
       "\n",
       "2. **Zookeeper Connectivity**: Kafka relies on Zookeeper for its cluster coordination. If Kafka cannot connect to Zookeeper, it will repeatedly attempt to connect, causing a restart loop.\n",
       "\n",
       "3. **Insufficient Resources**: If there are not enough system resources (like memory or disk space), Kafka may fail to start properly. Ensure that your system has adequate resources allocated.\n",
       "\n",
       "4. **Corrupted Log Segments**: If the log data for a topic is corrupted, Kafka might fail to start. This is particularly common if there was an unclean shutdown or disk failure.\n",
       "\n",
       "5. **Consumer Group Issues**: If there are issues with the consumer group, such as the offsets being out of bounds, this could cause the consumer to restart in an attempt to reset their state.\n",
       "\n",
       "6. **Java Exceptions**: If there are fatal exceptions in the Kafka logs related to network configuration, disk I/O, or data format issues, this can prevent proper startup and cause restarts.\n",
       "\n",
       "To troubleshoot, it's essential to review the Kafka log files for detailed error messages and stack traces that can offer insights into why it's failing. If you need assistance in addressing a specific issue, just let me know!</div></div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from IPython.display import display, HTML\n",
    "from semantic_kernel.contents import FunctionCallContent, FunctionResultContent, StreamingTextContent\n",
    "\n",
    "user_inputs = [\n",
    "    \"Simulate a NiFi error.\",\n",
    "    \"Explain why Kafka might be stuck in restart loop.\",\n",
    "]\n",
    "\n",
    "async def main():\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        html_output = (\n",
    "            f\"<div style='margin-bottom:10px'>\"\n",
    "            f\"<div style='font-weight:bold'>User:</div>\"\n",
    "            f\"<div style='margin-left:20px'>{user_input}</div></div>\"\n",
    "        )\n",
    "\n",
    "        agent_name = None\n",
    "        full_response: list[str] = []\n",
    "        function_calls: list[str] = []\n",
    "\n",
    "        current_function_name = None\n",
    "        argument_buffer = \"\"\n",
    "\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input,\n",
    "            thread=thread,\n",
    "        ):\n",
    "            thread = response.thread\n",
    "            agent_name = response.name\n",
    "            content_items = list(response.items)\n",
    "\n",
    "            for item in content_items:\n",
    "                if isinstance(item, FunctionCallContent):\n",
    "                    if item.function_name:\n",
    "                        current_function_name = item.function_name\n",
    "\n",
    "                    if isinstance(item.arguments, str):\n",
    "                        argument_buffer += item.arguments\n",
    "\n",
    "                elif isinstance(item, FunctionResultContent):\n",
    "                    if current_function_name:\n",
    "                        formatted_args = argument_buffer.strip()\n",
    "                        try:\n",
    "                            parsed_args = json.loads(formatted_args)\n",
    "                            formatted_args = json.dumps(parsed_args)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "\n",
    "                        function_calls.append(f\"Calling function: {current_function_name}({formatted_args})\")\n",
    "                        current_function_name = None\n",
    "                        argument_buffer = \"\"\n",
    "\n",
    "                    function_calls.append(f\"\\nFunction Result:\\n\\n{item.result}\")\n",
    "\n",
    "                elif isinstance(item, StreamingTextContent) and item.text:\n",
    "                    full_response.append(item.text)\n",
    "\n",
    "        if function_calls:\n",
    "            html_output += (\n",
    "                \"<div style='margin-bottom:10px'>\"\n",
    "                \"<details>\"\n",
    "                \"<summary style='cursor:pointer; font-weight:bold; color:#0066cc;'>Function Calls (click to expand)</summary>\"\n",
    "                \"<div style='margin:10px; padding:10px; background-color:#f8f8f8; \"\n",
    "                \"border:1px solid #ddd; border-radius:4px; white-space:pre-wrap; font-size:14px; color:#333;'>\"\n",
    "                f\"{chr(10).join(function_calls)}\"\n",
    "                \"</div></details></div>\"\n",
    "            )\n",
    "\n",
    "        html_output += (\n",
    "            \"<div style='margin-bottom:20px'>\"\n",
    "            f\"<div style='font-weight:bold'>{agent_name or 'Assistant'}:</div>\"\n",
    "            f\"<div style='margin-left:20px; white-space:pre-wrap'>{''.join(full_response)}</div></div><hr>\"\n",
    "        )\n",
    "\n",
    "        display(HTML(html_output))\n",
    "\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
