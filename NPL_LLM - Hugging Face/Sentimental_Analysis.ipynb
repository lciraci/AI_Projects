{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9da65c",
   "metadata": {},
   "source": [
    "This repository contains a sentiment analysis project using the DistilBERT model. Sentiment analysis involves classifying text data into different sentiment categories, such as positive (label-1), negative (label-0), or neutral (label-2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5c273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6f9b221d3c4b45a67a68ee80044e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/769 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6271eb79dd134772814e8839c8088801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915722ec98e040f0821a273c93c967b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415352e7be27421184584e48563d1b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5986ea1f8764c6bbe42ff3b841c43bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"Dmyadav2001/Sentimental-Analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fffed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love ChatGPT; it makes my work day so much easier!\n",
      "→ {'label': 'LABEL_1', 'score': 0.9457300901412964}\n",
      "\n",
      "This is the worst customer service I’ve ever experienced.\n",
      "→ {'label': 'LABEL_0', 'score': 0.9769734740257263}\n",
      "\n",
      "The movie was okay—nothing spectacular, nothing awful.\n",
      "→ {'label': 'LABEL_0', 'score': 0.8014140725135803}\n",
      "\n",
      "I’m furious that my order still hasn’t arrived!\n",
      "→ {'label': 'LABEL_0', 'score': 0.9363728761672974}\n",
      "\n",
      "Thank you for your quick response and help!\n",
      "→ {'label': 'LABEL_1', 'score': 0.9738197326660156}\n",
      "\n",
      "The package arrived late, but the support team was helpful.\n",
      "→ {'label': 'LABEL_1', 'score': 0.7528666257858276}\n",
      "\n",
      "Weather today is cloudy with a slight chance of rain.\n",
      "→ {'label': 'LABEL_0', 'score': 0.9389627575874329}\n",
      "\n",
      "Ugh, I’m so disappointed in this product.\n",
      "→ {'label': 'LABEL_0', 'score': 0.9596520066261292}\n",
      "\n",
      "Wow, that performance totally exceeded my expectations!\n",
      "→ {'label': 'LABEL_1', 'score': 0.8489273190498352}\n",
      "\n",
      "It’s fine, I guess—could be better, could be worse.\n",
      "→ {'label': 'LABEL_0', 'score': 0.689529538154602}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentences = [\n",
    "    \"I love ChatGPT; it makes my work day so much easier!\",           # → positive\n",
    "    \"This is the worst customer service I’ve ever experienced.\",      # → negative\n",
    "    \"The movie was okay—nothing spectacular, nothing awful.\",         # → neutral\n",
    "    \"I’m furious that my order still hasn’t arrived!\",                # → negative\n",
    "    \"Thank you for your quick response and help!\",                    # → positive\n",
    "    \"The package arrived late, but the support team was helpful.\",    # → mixed (often neutral/positive)\n",
    "    \"Weather today is cloudy with a slight chance of rain.\",          # → neutral\n",
    "    \"Ugh, I’m so disappointed in this product.\",                      # → negative\n",
    "    \"Wow, that performance totally exceeded my expectations!\",        # → positive\n",
    "    \"It’s fine, I guess—could be better, could be worse.\"             # → neutral\n",
    "]\n",
    "\n",
    "for s in test_sentences:\n",
    "    print(f\"{s}\\n→ {pipe(s)[0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37d4acd",
   "metadata": {},
   "source": [
    "manual batching, GPU moves, custom logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f75828e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I absolutely love this place!\n",
      "→ {'label': 'positive', 'score': 0.9804}\n",
      "\n",
      "This is the worst customer service ever.\n",
      "→ {'label': 'negative', 'score': 0.981}\n",
      "\n",
      "Eh, the movie was okay I guess.\n",
      "→ {'label': 'positive', 'score': 0.8186}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load weights + tokenizer  (~150 MB download the first time)\n",
    "model_name = \"Dmyadav2001/Sentimental-Analysis\"\n",
    "tokenizer   = AutoTokenizer.from_pretrained(model_name)\n",
    "model       = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()                        # turn off dropout\n",
    "# Optional: model.to(\"cuda\")  if you have a GPU\n",
    "\n",
    "# Map the numeric IDs back to human‑readable tags\n",
    "# Model card explains: label_0 = negative, label_1 = positive, label_2 = neutral :contentReference[oaicite:0]{index=0}\n",
    "id2label = {0: \"negative\", 1: \"positive\", 2: \"neutral\"}\n",
    "\n",
    "# Helper function\n",
    "def predict_sentiment(texts):\n",
    "    \"\"\"\n",
    "    texts: a string or a list of strings\n",
    "    returns list of dicts: {\"label\": \"...\", \"score\": float}\n",
    "    \"\"\"\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    # Tokenise *as a batch* so GPU/CPU vectorises efficiently\n",
    "    enc = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits              # shape [batch, 3]\n",
    "\n",
    "    probs = F.softmax(logits, dim=-1)             # turn scores into probabilities\n",
    "    preds = probs.argmax(dim=-1).tolist()         # highest‑probability class id\n",
    "    outputs = [\n",
    "        {\n",
    "            \"label\": id2label[p],                 # negative / positive / neutral\n",
    "            \"score\": round(probs[i, p].item(), 4) # confidence 0‑1\n",
    "        }\n",
    "        for i, p in enumerate(preds)\n",
    "    ]\n",
    "    return outputs if len(outputs) > 1 else outputs[0]\n",
    "\n",
    "# Quick smoke‑test\n",
    "samples = [\n",
    "    \"I absolutely love this place!\",\n",
    "    \"This is the worst customer service ever.\",\n",
    "    \"Eh, the movie was okay I guess.\"\n",
    "]\n",
    "for s, out in zip(samples, predict_sentiment(samples)):\n",
    "    print(f\"{s}\\n→ {out}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
